{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mohamm76/Identifying_facial_wrinkles/blob/main/FER_2013.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vhqQpwhURHGS"
      },
      "outputs": [],
      "source": [
        "# ØªØ«Ø¨ÙŠØª Ø§Ù„Ù€ kaggle (Ù„Ùˆ Ù„Ù… ÙŠÙƒÙ† Ù…Ø«Ø¨ØªØ§Ù‹) ÙˆØªØ£ÙƒØ¯ Ù…Ù† ÙˆØ¬ÙˆØ¯ ØµÙ„Ø§Ø­ÙŠØ§Øª\n",
        "!pip install -q kaggle\n",
        "\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mv \"/content/kaggle (1).json\" /content/kaggle.json\n"
      ],
      "metadata": {
        "id": "3muHgDewbHhq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import os\n",
        "\n",
        "kaggle_json_path = Path('/content/kaggle.json')\n",
        "\n",
        "if kaggle_json_path.exists():\n",
        "    os.makedirs('/root/.kaggle', exist_ok=True)\n",
        "    !cp /content/kaggle.json /root/.kaggle/\n",
        "    !chmod 600 /root/.kaggle/kaggle.json\n",
        "    print('âœ… kaggle.json moved to /root/.kaggle and permissions set.')\n",
        "else:\n",
        "    print('âŒ Ù„Ù… Ø£Ø¬Ø¯ kaggle.json ÙÙŠ /content â€” Ø§Ø±ÙØ¹ Ù…Ù„Ù kaggle.json Ø«Ù… Ø£Ø¹Ø¯ ØªØ´ØºÙŠÙ„ Ù‡Ø°Ù‡ Ø§Ù„Ø®Ù„ÙŠØ©.')\n",
        "\n"
      ],
      "metadata": {
        "id": "TWBdn7nIXFcx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ØªÙ†Ø²ÙŠÙ„ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø¨ÙŠØ§Ù†Ø§Øª FER-2013 Ù…Ù† Kaggle\n",
        "\n",
        "!kaggle datasets download -d msambare/fer2013 -q --unzip"
      ],
      "metadata": {
        "id": "r19wN65zbYR6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ù…Ø§ ÙØ§Ø¦Ø¯Ø© Ø§Ù„Ù…ÙˆÙ„Ø¯ (ImageDataGenerator)ØŸ\n",
        "\n",
        "Ø§Ù„ÙÙƒØ±Ø© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© ğŸ‘‡\n",
        "Ø¨Ø¯Ù„Ù‹Ø§ Ù…Ù† ØªØ­Ù…ÙŠÙ„ ÙƒÙ„ Ø§Ù„ØµÙˆØ± Ø¥Ù„Ù‰ Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ø¯ÙØ¹Ø© ÙˆØ§Ø­Ø¯Ø© (ÙˆÙ‡Ùˆ Ù…Ø³ØªØ­ÙŠÙ„ Ø£Ø­ÙŠØ§Ù†Ù‹Ø§ Ø¹Ù†Ø¯Ù…Ø§ ØªÙƒÙˆÙ† Ø¢Ù„Ø§Ù Ø§Ù„ØµÙˆØ±)ØŒ ÙŠÙ‚ÙˆÙ… Ø§Ù„Ù…ÙˆÙ„Ø¯ Ø¨ØªØ­Ù…ÙŠÙ„ Ø¯ÙØ¹Ø§Øª ØµØºÙŠØ±Ø© (batches) Ù…Ù† Ø§Ù„ØµÙˆØ± Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ ÙÙ‚Ø·.\n",
        "\n",
        "ğŸ”¹ Ø£ÙŠ Ø£Ù†Ù‡:\n",
        "\n",
        "ÙŠÙ‚Ø±Ø£ Ø§Ù„ØµÙˆØ± Ù…Ù† Ø§Ù„Ù…Ø¬Ù„Ø¯ Ù…Ø¨Ø§Ø´Ø±Ø©.\n",
        "\n",
        "ÙŠØ·Ø¨Ù‘Ù‚ Ø¹Ù„ÙŠÙ‡Ø§ Ø§Ù„ØªØ­Ø³ÙŠÙ†Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© (Ù…Ø«Ù„ Ø§Ù„ØªØ¯ÙˆÙŠØ±ØŒ Ø§Ù„Ù‚ØµØŒ Ø§Ù„ØªØ·Ø¨ÙŠØ¹).\n",
        "\n",
        "ÙŠØ±Ø³Ù„Ù‡Ø§ Ø¥Ù„Ù‰ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¹Ù„Ù‰ Ø´ÙƒÙ„ Ø¯ÙØ¹Ø§Øª (batch) Ø¨Ø´ÙƒÙ„ Ù…Ø³ØªÙ…Ø± Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„ØªØ¯Ø±ÙŠØ¨.\n",
        "\n",
        "ÙˆÙ‡Ø°Ø§ Ù…Ø§ ÙŠÙØ³Ù…Ù‘Ù‰ Ø¨Ù€ Ø§Ù„ØªØºØ°ÙŠØ© Ø§Ù„ÙƒØ³ÙˆÙ„Ø© (lazy loading) Ø£Ùˆ Ø§Ù„ØªØºØ°ÙŠØ© Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„ØªØ¯Ø±ÙŠØ¨."
      ],
      "metadata": {
        "id": "p_ZTk4NtsaUP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import layers, models\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "#Ø¥Ù†Ø´Ø§Ø¡ Ù…ÙˆÙ„Ø¯ (generator) ÙŠÙ‚ÙˆÙ… Ø¨Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„ØµÙˆØ± Ù…Ù† Ø§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª Ù…Ø¹ Ø¥Ù…ÙƒØ§Ù†ÙŠØ© ØªØ­Ø³ÙŠÙ†Ù‡Ø§ Ø£Ùˆ ØªØ¹Ø¯ÙŠÙ„Ù‡Ø§ (augmentation) Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„ØªØ¯Ø±ÙŠØ¨.\n",
        "IMG_SIZE = 48 #Ø­Ø¬Ù… Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨ Ø¹Ù†Ø¯ Ø¥Ø¯Ø®Ø§Ù„Ù‡Ø§ Ù„Ù„Ù†Ù…ÙˆØ°Ø¬ (ÙƒÙ„ ØµÙˆØ±Ø© Ø³ÙŠØªÙ… ØªØ­ÙˆÙŠÙ„Ù‡Ø§ Ø¥Ù„Ù‰ 48Ã—48 Ø¨ÙƒØ³Ù„).\n",
        "BATCH_SIZE = 32 #Ø¹Ø¯Ø¯ Ø§Ù„ØµÙˆØ± Ø§Ù„ØªÙŠ Ø³ØªÙØ¹Ø§Ù„Ø¬ Ø¯ÙØ¹Ø© ÙˆØ§Ø­Ø¯Ø© ÙÙŠ ÙƒÙ„ Ø®Ø·ÙˆØ© ØªØ¯Ø±ÙŠØ¨ (batch size = 32).\n",
        "\n",
        "# Ø¥Ù†Ø´Ø§Ø¡ Ù…ÙˆÙ„Ø¯ Ù„Ù„ØµÙˆØ± Ù…Ø¹ Ø§Ù„ØªÙˆØ³ÙŠØ¹ augmentation\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255, #ØªØ·Ø¨ÙŠØ¹ Ø§Ù„ØµÙˆØ± Ø¨ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù‚ÙŠÙ… Ù…Ù† [0,255] Ø¥Ù„Ù‰ [0,1] Ù„ØªØ³Ø±ÙŠØ¹ Ø§Ù„ØªØ¹Ù„Ù….\n",
        "    rotation_range=10, #ØªØ¯ÙˆÙŠØ± Ø§Ù„ØµÙˆØ±Ø© Ø¹Ø´ÙˆØ§Ø¦ÙŠÙ‹Ø§ Ø¨Ø²Ø§ÙˆÙŠØ© ØªØµÙ„ Ø¥Ù„Ù‰ Â±10 Ø¯Ø±Ø¬Ø§Øª.\n",
        "    width_shift_range=0.1, #ØªØ­Ø±ÙŠÙƒ Ø§Ù„ØµÙˆØ±Ø© Ø£ÙÙ‚ÙŠÙ‹Ø§ Ø¨Ù†Ø³Ø¨Ø© 10% Ù…Ù† Ø¹Ø±Ø¶Ù‡Ø§.\n",
        "    height_shift_range=0.1,#ØªØ­Ø±ÙŠÙƒ Ø§Ù„ØµÙˆØ±Ø© Ø¹Ù…ÙˆØ¯ÙŠÙ‹Ø§ Ø¨Ù†Ø³Ø¨Ø© 10%.\n",
        "    horizontal_flip=True #Ù‚Ù„Ø¨ Ø§Ù„ØµÙˆØ±Ø© Ø£ÙÙ‚ÙŠÙ‹Ø§ Ø¹Ø´ÙˆØ§Ø¦ÙŠÙ‹Ø§.\n",
        "\n",
        "  #Ø§Ù„Ù‡Ø¯Ù: Ø¬Ø¹Ù„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙŠØ±Ù‰ ØªÙ†ÙˆØ¹Ù‹Ø§ Ø£ÙƒØ¨Ø± ÙÙŠ Ù†ÙØ³ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (Ø²ÙŠØ§Ø¯Ø© Ø§Ù„Ù‚Ø¯Ø±Ø© Ø¹Ù„Ù‰ Ø§Ù„ØªØ¹Ù…ÙŠÙ…).\n",
        ")\n",
        "\n",
        "\n",
        "'''\n",
        "ğŸ”¹ Ù‡Ù†Ø§ Ù…ÙˆÙ„Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„Ø§Ø®ØªØ¨Ø§Ø± ÙÙ‚Ø·ØŒ\n",
        "Ù„ÙƒÙ† Ø¨Ø¯ÙˆÙ† Ø£ÙŠ ØªØ¹Ø¯ÙŠÙ„ (augmentation) Ù„Ø£Ù†Ù†Ø§ Ù†Ø±ÙŠØ¯ ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¹Ù„Ù‰ Ø§Ù„ØµÙˆØ± Ø§Ù„Ø£ØµÙ„ÙŠØ© ÙÙ‚Ø·.\n",
        "Ù†ÙƒØªÙÙŠ Ø¨ØªØ·Ø¨ÙŠØ¹ Ø§Ù„Ù‚ÙŠÙ… [0,1].\n",
        "'''\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "\n",
        "#Ù‡Ø°Ø§ Ø§Ù„Ø³Ø·Ø± ÙŠÙ†Ø´Ø¦ Ù…ÙˆÙ„Ø¯ ÙØ¹Ù„ÙŠ Ù„Ù„ØµÙˆØ± Ø§Ù„ØªØ¯Ø±ÙŠØ¨ÙŠØ© ÙŠÙ‚Ø±Ø£ Ø§Ù„ØµÙˆØ± Ù…Ù† Ø§Ù„Ù…Ø¬Ù„Ø¯ training/.\n",
        "# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Ø§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    '/content/train',          # Ù…Ø³Ø§Ø± Ù…Ø¬Ù„Ø¯ Ø§Ù„ØªØ¯Ø±ÙŠØ¨\n",
        "    target_size=(IMG_SIZE, IMG_SIZE), #ÙŠØºÙŠØ± Ø­Ø¬Ù… ÙƒÙ„ ØµÙˆØ±Ø© Ø¥Ù„Ù‰ 48Ã—48 Ø¨ÙƒØ³Ù„.\n",
        "    color_mode='grayscale',  # Ù„Ø£Ù† ØµÙˆØ± FER-2013 Ø£Ø¨ÙŠØ¶ ÙˆØ£Ø³ÙˆØ¯\n",
        "    batch_size=BATCH_SIZE, #ÙŠØ¹ÙŠØ¯ 32 ØµÙˆØ±Ø© ÙÙŠ ÙƒÙ„ Ø¯ÙØ¹Ø© ØªØ¯Ø±ÙŠØ¨.\n",
        "    class_mode='categorical'\n",
        "    #ÙŠØ¹Ù†ÙŠ Ø£Ù† Ø§Ù„ØªØµÙ†ÙŠÙØ§Øª Ø³ØªÙƒÙˆÙ† one-hot encoded (Ù…Ø«Ù„ [0,0,1,0,0,0,0] Ù„ØªØµÙ†ÙŠÙ Ø§Ù„ÙˆØ¬Ù‡).\n",
        ")\n",
        "\n",
        "#the same train data\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    '/content/test',             # Ù…Ø³Ø§Ø± Ù…Ø¬Ù„Ø¯ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±\n",
        "    target_size=(IMG_SIZE, IMG_SIZE),\n",
        "    color_mode='grayscale',\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False        # Ù„Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ ØªØ±ØªÙŠØ¨ Ø§Ù„ØµÙˆØ± ÙÙŠ Ø§Ù„ØªÙ‚ÙŠÙŠÙ…\n",
        "\n",
        " )\n",
        "\n",
        "  #shuffle=False: ÙŠØ¹Ù†ÙŠ Ù„Ø§ Ù†Ø®Ù„Ø· ØªØ±ØªÙŠØ¨ Ø§Ù„ØµÙˆØ±\n",
        " # (Ø­ØªÙ‰ Ù†Ø­Ø§ÙØ¸ Ø¹Ù„Ù‰ ØªØ±ØªÙŠØ¨Ù‡Ø§ Ø§Ù„Ø£ØµÙ„ÙŠ Ø¹Ù†Ø¯ Ø­Ø³Ø§Ø¨ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø£Ùˆ Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø© Ù…Ø¹ Ø§Ù„ØªØ³Ù…ÙŠØ§Øª Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠØ©).\n",
        "\n",
        "\n",
        "EPOCHS = 25\n",
        "\n",
        "#Ù‡Ù†Ø§ Ù†Ø­ØµÙ„ Ø¹Ù„Ù‰ Ø¹Ø¯Ø¯ Ø§Ù„ÙØ¦Ø§Øª (classes) ØªÙ„Ù‚Ø§Ø¦ÙŠÙ‹Ø§ Ù…Ù† Ø§Ù„Ù…ÙˆÙ„Ø¯ train_generator.\n",
        "#train_generator.class_indices â†’ Ù‚Ø§Ù…ÙˆØ³ ÙŠØ±Ø¨Ø· Ø§Ø³Ù… ÙƒÙ„ ÙØ¦Ø© Ø¨Ø±Ù‚Ù….\n",
        "#len(...) â†’ Ø¹Ø¯Ø¯ Ø§Ù„ÙØ¦Ø§Øª Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠ.\n",
        "#Ù†Ø·Ø¨Ø¹Ù‡ Ù„ØªØ£ÙƒÙŠØ¯ Ø¹Ø¯Ø¯ Ø£ØµÙ†Ø§Ù Ø§Ù„ÙˆØ¬Ù‡ Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø© ÙÙŠ  dataset\n",
        "num_classes = len(train_generator.class_indices)\n",
        "print(\"Ø¹Ø¯Ø¯ Ø§Ù„ÙØ¦Ø§Øª:\", num_classes)\n",
        "\n",
        "# ===== Ø¨Ù†Ø§Ø¡ Ù†Ù…ÙˆØ°Ø¬ CNN Ø¨Ø³ÙŠØ· =====\n",
        "input_shape = (IMG_SIZE, IMG_SIZE, 1)#ØªØ­Ø¯ÙŠØ¯ Ø´ÙƒÙ„ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø¯Ø§Ø®Ù„Ø© Ù„Ù„Ù†Ù…ÙˆØ°Ø¬ (Ø§Ù„Ø¹Ø±Ø¶  Ø§Ù„Ø¥Ø±ØªÙØ§Ø¹ Ù‚Ù†Ø§Øª Ø§Ù„Ù„ÙˆÙ† )\n",
        "\n",
        "model = models.Sequential([\n",
        "    layers.Input(shape=input_shape),#ÙŠØ­Ø¯Ø¯ Ø´ÙƒÙ„ Ø§Ù„Ù…Ø¯Ø®Ù„Ø§Øª.\n",
        "\n",
        "    layers.Conv2D(32, (3,3), activation='relu', padding='same'),\n",
        "    #padding='same' â†’ ÙŠØ¶Ù…Ù† Ø¨Ù‚Ø§Ø¡ Ø£Ø¨Ø¹Ø§Ø¯ Ø§Ù„ØµÙˆØ±Ø© Ø¨Ø¹Ø¯ Ø§Ù„Ø§Ù„ØªÙØ§Ù Ù†ÙØ³Ù‡Ø§.\n",
        "    layers.BatchNormalization(),\n",
        "    #ÙŠØ­Ø³Ù† Ø³Ø±Ø¹Ø© Ø§Ù„ØªØ¯Ø±ÙŠØ¨ ÙˆÙŠÙ‚Ù„Ù„ Ø§Ù„Ù€ overfitting Ø¹Ù† Ø·Ø±ÙŠÙ‚ ØªÙˆØ­ÙŠØ¯ ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ù‚ÙŠÙ… Ø¯Ø§Ø®Ù„ ÙƒÙ„ batch.\n",
        "    layers.MaxPooling2D((2,2)),\n",
        "    #ØªÙ‚Ù„ÙŠÙ„ Ø£Ø¨Ø¹Ø§Ø¯ Ø§Ù„ØµÙˆØ±Ø© (downsampling) Ø¥Ù„Ù‰ Ø§Ù„Ù†ØµÙ.\n",
        "    #ÙŠØ­Ø§ÙØ¸ Ø¹Ù„Ù‰ Ø£Ù‡Ù… Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø§Ù„Ù…Ù…ÙŠØ²Ø©.\n",
        "\n",
        "    #Ù†ÙØ³ Ø§Ù„ÙÙƒØ±Ø© Ø§Ù„Ø³Ø§Ø¨Ù‚Ø© Ù„ÙƒÙ† Ø¹Ø¯Ø¯ Ø§Ù„ÙÙ„Ø§ØªØ± Ø²Ø§Ø¯ Ø¥Ù„Ù‰ 64 â†’ ØªØ¹Ù„Ù… Ù…ÙŠØ²Ø§Øª Ø£ÙƒØ«Ø± ØªØ¹Ù‚ÙŠØ¯Ù‹Ø§.\n",
        "    layers.Conv2D(64, (3,3), activation='relu', padding='same'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.MaxPooling2D((2,2)),\n",
        "    #Dropout(0.25) â†’ Ø¥ÙŠÙ‚Ø§Ù 25% Ù…Ù† Ø§Ù„Ø®Ù„Ø§ÙŠØ§ Ø¹Ø´ÙˆØ§Ø¦ÙŠÙ‹Ø§ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ù„ØªÙ‚Ù„ÙŠÙ„ Ø§Ù„Ù€ overfitting.\n",
        "    layers.Dropout(0.25),\n",
        "\n",
        "    #Ø¹Ø¯Ø¯ Ø§Ù„ÙÙ„Ø§ØªØ± Ø£ØµØ¨Ø­ 128 â†’ ØªÙ…Ø«ÙŠÙ„ Ù…ÙŠØ²Ø§Øª Ø£ÙƒØ«Ø± ØªØ¹Ù‚ÙŠØ¯Ù‹Ø§.\n",
        "    #Ù†ÙØ³ Ø®Ø·ÙˆØ§Øª Normalization, Pooling, Dropout.\n",
        "    layers.Conv2D(128, (3,3), activation='relu', padding='same'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.MaxPooling2D((2,2)),\n",
        "    layers.Dropout(0.25),\n",
        "\n",
        "    #Flatten() â†’ ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù…Ø®Ø±Ø¬Ø§Øª Ø«Ù†Ø§Ø¦ÙŠØ© Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯ Ù…Ù† Conv Ø¥Ù„Ù‰ Ù…ØªØ¬Ù‡ 1D Ù„ÙŠØªÙ… Ø¥Ø¯Ø®Ø§Ù„Ù‡Ø§ Ù„Ù„Ù€ Dense.\n",
        "    layers.Flatten(),\n",
        "    #Dense(128, activation='relu') â†’ Ø·Ø¨Ù‚Ø© fully connected Ø¨Ù‡Ø§ 128 Ø®Ù„ÙŠØ© Ù„ØªØ¬Ù…ÙŠØ¹ Ø§Ù„Ù…ÙŠØ²Ø§Øª.\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    #BatchNormalization() + Dropout(0.5) â†’ ØªÙˆØ­ÙŠØ¯ Ø§Ù„Ù‚ÙŠÙ… ÙˆØªÙ‚Ù„ÙŠÙ„ overfitting.\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Dropout(0.5),\n",
        "    #Dense(num_classes, activation='softmax') â†’ Ø·Ø¨Ù‚Ø© Ø§Ù„Ø¥Ø®Ø±Ø§Ø¬.\n",
        "    layers.Dense(num_classes, activation='softmax')\n",
        "])\n",
        "#ØªØ¬Ù…ÙŠØ¹ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬\n",
        "#optimizer='adam' â†’ Ø®ÙˆØ§Ø±Ø²Ù…ÙŠØ© ØªØ­Ø³ÙŠÙ† ØªÙ„Ù‚Ø§Ø¦ÙŠØ© ÙØ¹Ø§Ù„Ø©.\n",
        "#loss='categorical_crossentropy' â†’ Ù…Ù†Ø§Ø³Ø¨Ø© Ù„ØªØµÙ†ÙŠÙ Ù…ØªØ¹Ø¯Ø¯ Ø§Ù„ÙØ¦Ø§Øª.\n",
        "#metrics=['accuracy'] â†’ Ù†Ø±Ø§Ù‚Ø¨ Ø¯Ù‚Ø© Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„ØªØ¯Ø±ÙŠØ¨.\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n"
      ],
      "metadata": {
        "id": "vl--S-uvdZD4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ =====\n",
        "callbacks = [\n",
        "    # ØªÙ‚Ù„ÙŠÙ„ Ù…Ø¹Ø¯Ù„ Ø§Ù„ØªØ¹Ù„Ù… Ø¥Ø°Ø§ ØªÙˆÙ‚ÙØª Ø§Ù„Ø®Ø³Ø§Ø±Ø© Ø¹Ù† Ø§Ù„ØªØ­Ø³Ù†\n",
        "    tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6, verbose=1),\n",
        "    # Ø¥ÙŠÙ‚Ø§Ù Ù…Ø¨ÙƒØ± Ø¹Ù†Ø¯ Ø¹Ø¯Ù… Ø§Ù„ØªØ­Ø³Ù†\n",
        "    tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=8, restore_best_weights=True, verbose=1)\n",
        "]\n",
        "\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=test_generator,\n",
        "    epochs=EPOCHS,\n",
        "    callbacks=callbacks\n",
        ")\n"
      ],
      "metadata": {
        "id": "URVbU07Ux3Tu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== Ø±Ø³Ù… Ø§Ù„Ø®Ø³Ø§Ø±Ø© ÙˆØ§Ù„Ø¯Ù‚Ø© =====\n",
        "plt.figure(figsize=(12,4))\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(history.history['loss'], label='train_loss')\n",
        "plt.plot(history.history['val_loss'], label='val_loss')\n",
        "plt.title('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(history.history['accuracy'], label='train_acc')\n",
        "plt.plot(history.history['val_accuracy'], label='val_acc')\n",
        "plt.title('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1vgm4A00NVNP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ =====\n",
        "test_generator.reset()\n",
        "y_pred_probs = model.predict(test_generator)\n",
        "y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "y_true = test_generator.classes\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.heatmap(cm, annot=True, fmt='d')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "\n",
        "print(classification_report(y_true, y_pred, target_names=list(train_generator.class_indices.keys())))"
      ],
      "metadata": {
        "id": "KN7cOS5RNv9j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== Ø­ÙØ¸ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ =====\n",
        "model.save('fer2013_cnn_model.h5')\n",
        "print('âœ… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ØªÙ… Ø­ÙØ¸Ù‡ Ø¨Ø§Ø³Ù… fer2013_cnn_model.h5')"
      ],
      "metadata": {
        "id": "xYCEvKHPOSex"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. ØªØ«Ø¨ÙŠØª Ø§Ù„Ù…ÙƒØªØ¨Ø© Ø£ÙˆÙ„Ø§Ù‹ (Ø¥Ø°Ø§ Ù„Ù… ØªÙƒÙ† Ù‚Ø¯ Ø«Ø¨ØªÙ‡Ø§ ÙÙŠ Ù‡Ø°Ù‡ Ø§Ù„Ø¬Ù„Ø³Ø©)\n",
        "!pip install gradio\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "import gradio as gr\n",
        "from PIL import Image\n",
        "\n",
        "# 2. ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø°ÙŠ Ø±ÙØ¹ØªÙ‡ ÙŠØ¯ÙˆÙŠØ§Ù‹ Ù…Ù† Ø¬Ù‡Ø§Ø²Ùƒ\n",
        "# Ù…Ù„Ø§Ø­Ø¸Ø©: ØªØ£ÙƒØ¯ Ø£Ù† Ø§Ù„Ø§Ø³Ù… Ù…Ø·Ø§Ø¨Ù‚ Ù„Ù„Ù…Ù„Ù Ø§Ù„Ø°ÙŠ Ø±ÙØ¹ØªÙ‡ (fer2013_cnn_model.h5)\n",
        "try:\n",
        "    model = load_model('fer2013_cnn_model.h5')\n",
        "    print(\"âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¨Ù†Ø¬Ø§Ø­!\")\n",
        "except:\n",
        "    print(\"âŒ Ø®Ø·Ø£: Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…Ù„Ù Ø§Ù„Ù†Ù…ÙˆØ°Ø¬. ØªØ£ÙƒØ¯ Ù…Ù† Ø±ÙØ¹Ù‡ ÙÙŠ Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù…Ù„ÙØ§Øª ÙŠÙ…ÙŠÙ†Ø§Ù‹.\")\n",
        "\n",
        "# 3. ØªØ¹Ø±ÙŠÙ Ø§Ù„Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø¨Ø±Ù…Ø¬ÙŠØ© Ù„Ù„Ù…Ø´Ø§Ø¹Ø±\n",
        "class_labels = ['Angry', 'Disgust', 'Fear', 'Happy', 'Neutral', 'Sad', 'Surprise']\n",
        "\n",
        "def predict_emotion(input_img):\n",
        "    if input_img is None:\n",
        "        return \"Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø±ÙØ¹ ØµÙˆØ±Ø©\"\n",
        "\n",
        "    # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ±Ø©: ØªØ­ÙˆÙŠÙ„ Ù„Ø±Ù…Ø§Ø¯ÙŠØŒ ØªØºÙŠÙŠØ± Ø§Ù„Ø­Ø¬Ù… Ù„Ù€ 48x48ØŒ Ø«Ù… ØªØ·Ø¨ÙŠØ¹ Ø§Ù„Ù‚ÙŠÙ…\n",
        "    img = Image.fromarray(input_img.astype('uint8'), 'RGB')\n",
        "    img = img.convert('L')\n",
        "    img = img.resize((48, 48))\n",
        "\n",
        "    img_array = img_to_array(img)\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "    img_array = img_array / 255.0\n",
        "\n",
        "    # Ø§Ù„ØªÙ†Ø¨Ø¤\n",
        "    prediction = model.predict(img_array)[0]\n",
        "\n",
        "    # Ø¥Ø±Ø¬Ø§Ø¹ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ÙƒÙ‚Ø§Ù…ÙˆØ³ Ù„Ø¹Ø±Ø¶Ù‡Ø§ ÙÙŠ Ø§Ù„ÙˆØ§Ø¬Ù‡Ø©\n",
        "    return {class_labels[i]: float(prediction[i]) for i in range(len(class_labels))}\n",
        "\n",
        "# 4. Ø¥Ø¹Ø¯Ø§Ø¯ ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…\n",
        "interface = gr.Interface(\n",
        "    fn=predict_emotion,\n",
        "    inputs=gr.Image(),\n",
        "    outputs=gr.Label(num_top_classes=3, label=\"Ø§Ù„ØªÙˆÙ‚Ø¹Ø§Øª\"),\n",
        "    title=\"Ù†Ø¸Ø§Ù… Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ù…Ø´Ø§Ø¹Ø± Ø§Ù„ÙˆØ¬Ù‡ ğŸ§ \",\n",
        "    description=\"Ø§Ø±ÙØ¹ ØµÙˆØ±Ø© ÙˆØ¬Ù‡Ùƒ Ù‡Ù†Ø§ ÙˆØ³ÙŠÙ‚ÙˆÙ… Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ø¨ØªØ­Ù„ÙŠÙ„ Ù…Ø´Ø§Ø¹Ø±Ùƒ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø±ÙÙˆØ¹.\"\n",
        ")\n",
        "\n",
        "# 5. Ø§Ù†Ø·Ù„Ø§Ù‚ Ø§Ù„ÙˆØ§Ø¬Ù‡Ø©\n",
        "interface.launch(share=True)"
      ],
      "metadata": {
        "id": "zpigwG_OzK2u",
        "outputId": "8dbd4423-53bc-4233-8cfb-86ae3da46eca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gradio in /usr/local/lib/python3.12/dist-packages (5.50.0)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.12.0)\n",
            "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.2.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.123.10)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.12/dist-packages (from gradio) (1.0.0)\n",
            "Requirement already satisfied: gradio-client==1.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.14.0)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx<1.0,>=0.24.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=0.33.5 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.36.0)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.0.3)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.11.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from gradio) (25.0)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (11.3.0)\n",
            "Requirement already satisfied: pydantic<=2.12.3,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.12.3)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.12/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (6.0.3)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.14.9)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.7)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.50.0)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.20.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.15.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.38.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.14.0->gradio) (2025.3.0)\n",
            "Requirement already satisfied: websockets<16.0,>=13.0 in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.14.0->gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (3.11)\n",
            "Requirement already satisfied: annotated-doc>=0.0.2 in /usr/local/lib/python3.12/dist-packages (from fastapi<1.0,>=0.115.2->gradio) (0.0.4)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (3.20.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (1.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<=2.12.3,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<=2.12.3,>=2.0->gradio) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<=2.12.3,>=2.0->gradio) (0.4.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (8.3.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<2.0,>=0.33.5->gradio) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<2.0,>=0.33.5->gradio) (2.5.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¨Ù†Ø¬Ø§Ø­!\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://8131183e754c17ebfb.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://8131183e754c17ebfb.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vrlqzxnE0H2g"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}